Space exploration is hard. One of the reasons for this is the distance. Despite the speed of light being incredibly fast to us, the universe is very big. The radio propagation time between Earth and a rover on Mars, for example, can be anywhere between 4 minutes and 24 minutes, depending on the time of (each planet's) year. 

The distance also means enormous free space path loss - For example, an S band transmission experiences between 257 and 274 dB of loss. This greatly reduces the Shannon capacity of the communication channel, reducing the amount of science data which can be returned.
----
Thus, autonomy is crucial in overcoming these barriers. We can create relatively high level, autonomous controllers which we issue high-level instructions such as "Go to that interesting rock", and expect it to navigate its way around a crater enroute without any human interaction. 

We can also preprocess the collected data, such as creating and transmitting only a histogram of the data, rather than the individual datapoints. Of course, we can also compress it.
----
There are two main, complimentary approaches to the creation of autonomous systems: Control theory, which is suited to low-level systems when both the plant and desired behaviour are relatively easy to mathematically model, and so-called artificial intelligence, which is suitable when we find great difficulty in modeling the plant, but can still describe the desired behaviour.

It is desirable to make our robotic cosmonauts as autonomous as possible, so ideally we could just instruct them to "go do some science and report any interesting discoveries". But how can we mathematically model "Go do some science", or, for that matter, "interesting discovery"?


 
* Planetary rovers, and other space science platforms, are increasingly being designed to maximise their autonomy.
* This requires mathematically describing desired high level behaviours.
* But how do we mathematically describe "do some science" when we don't know what we are looking for?
----

[ * Let's define science as systematic curiosity.
    - But this is just shifting the goalposts
    - So what is curiosity?
]

* Curiosity as a behaviour may be described as trying to maximise interestingness.
* We aren't curious about things which are completely predictable, nor about things which appear completely random
----

[ * This is the realm of information theory.
    - Tools to study causal processes and feedback, such as physical processes, are less developed
    - One such tool is directed information theory
]

* Thus, interestingness is a nonmonotonic measure of similarity to previously understood, or modeled, information

----

[ * Compression theory is a subfield of information theory
    - We know how to (practically) optimally encode data given a probabilistic generative model
    - Thus compression theory focuses on techniques to produce probabilistic models of data

FN: Coherence progress paper, Artificial Curiosity in Space Exploration paper, Lossless Data Compression thesis, Matt Mahoney compression and AI page]

* Compression works by finding and exploiting similarity in the given data by creating probabilistic models
* This is exactly why we want the data - to analyse it to discover and model the process which creates it
* This means we can use compression to formalise curiosity, for example, coherence progress.
----

[ * This realisation leads to interesting questions, such as:
    - How can we use these models for the purpose of science?
    - Or use them to improve the autonomy of our hypothetical robotic cosmonaut?
    - Is the resulting compressed data suitable for transmission to Earth?

]

* Most extant compression doesn't actively ask for additional data (meaning, in our case, perform more experiments) to improve its models
* We propose to investigate pro-active, physically-based compression schemes for use in autonomous agents.
----

[ * Major risks
    - Schedule slippage due to bugs
    - Difficulty interfacing with regression applications
    - Finding a suitable formulation for actions available to the agent
FN: Eureqa]

* We shall create a test application in Haskell which simulates experimental data with a damped oscillator plus noise, and passes it on to physically-based regression applications. Then, we'll take the resulting models, arithmetically code the data, and, if compression is poor, prompt for additional data. We measure our increasingly complex models in terms of coherence progress.

* Then, we shall broaden the types of available simulated data (for example, a projectile) and attempt to train an autonomous agent via reinforcement learning with coherence progress as a reward metric.