* Space exploration is hard
* One of the reasons for this is significant latency
* Therefore, autonomy is very helpful
* How do we create autonomous systems?
* Typically, one creates a system which may take many different actions, and use design a control system to choose which action to take and when
* Two major approaches: control theory and artificial intelligence
* Control theory works great when we can mathematically formalise the system, its environment, and the desired behaviour; in other words, it's a bottom-up approach
* Artificial intelligence can be described as a top-down approach, and provides techniques to use when the problem is hard to mathematically characterise
* But we still have the problem of trying to describe the desired behaviour
===========

[ * Interplanetary space exploration is hard.
    - One reason is due to high latency. The speed of light is terribly slow.
    - Thus, it is desirable to reduce human interaction with robotic cosmonauts as much as possible
    - But describing high-level behaviours is very hard
]
 
* Planetary rovers, and other space science platforms, are increasingly being designed to maximise their autonomy.
* This requires mathematically describing desired behaviours.
* But how do we mathematically describe "do some science" when we don't know what we are looking for?
----

[ * Let's define science as systematic curiosity.
    - But this is just shifting the goalposts
    - So what is curiosity?
]

* Curiosity as a behaviour may be described as trying to maximising interestingness.
* We aren't curious about things which are completely predictable, nor about things which appear completely random
----

[ * This is the realm of information theory.
    - Tools to study causal processes and feedback, such as physical processes, are less developed
    - One such tool is directed information theory
]

* Thus, interestingness is a nonmonotonic measure of similarity to previously understood, or modeled, information

----

[ * Compression theory is a subfield of information theory
    - We know how to (practically) optimally encode data given a probabilistic generative model
    - Thus compression theory focuses on techniques to produce probabilistic models of data

FN: Coherence progress paper, Artificial Curiosity in Space Exploration paper, Lossless Data Compression thesis, Matt Mahoney compression and AI page]

* Compression works by finding and exploiting similarity in the given data by creating probabilistic models
* This is exactly why we want the data - to analyse it to discover and model the process which creates it
* This means we can use compression to formalise curiosity, for example, coherence progress.
----

[ * This realisation leads to interesting questions, such as:
    - How can we use these models for the purpose of science?
    - Or use them to improve the autonomy of our hypothetical robotic cosmonaut?
    - Is the resulting compressed data suitable for transmission to Earth?

]

* Most extant compression doesn't actively ask for additional data (meaining, in our case, perform more experiments) to improve its models
* We propose to investigate pro-active, physically-based compression schemes for use in autonomous agents.
----

[ * Risks
    - Schedule slippage due to bugs
    -  
FN: Eureqa]

* We shall create a test application in Haskell which simulates experimental data with a damped oscillator plus noise, and passes it on to physically-based regression applications. Then, we'll take the resulting models, arithmetically code the data, and, if compression is poor, prompt for additional data. We measure our increasingly complex models in terms of coherence progress.

* Then, we shall broaden the types of available simulated data (for example, a projectile) and attempt to train an autonomous agent via reinforcement learning with coherence progress as a reward metric.